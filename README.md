# AR+TypoFusion: <br> 
# A Personalized ML Tool to Explore Co-Creativity within Personal Arabic Typography Practice

Visualize and bring your typography to life! 
AR+TypoFusion is a personalized adaptation of the popular Stable Diffusion model that can perform conditional Arabic typography-to-image translation. 
<br><br>

## Video Documentation: https://vimeo.com/773337985

![interpolated (27)](https://user-images.githubusercontent.com/92052904/202871983-25fea1ff-d687-4521-a0bd-ad8858daeedd.gif)
![interpolated (30)](https://user-images.githubusercontent.com/92052904/203102467-b9daa366-833c-49f0-aa71-c1ad402a8ac9.gif)

![Asset 51-100](https://user-images.githubusercontent.com/92052904/203107227-0d207d04-3f55-437c-85c6-b389ce2054ff.jpg)

## Attributions
This project is built around the Stable Diffusion model created by StabilityAI and Runway. 

Model Details

Developed by: Robin Rombach, Patrick Esser
Model type: Diffusion-based text-to-image generation model
Language(s): English
License: The CreativeML OpenRAIL M license is an Open RAIL M license, adapted from the work that BigScience and the RAIL Initiative are jointly carrying in the area of responsible AI licensing. See also the article about the BLOOM Open RAIL license on which our license is based.
Model Description: This is a model that can be used to generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (CLIP ViT-L/14) as suggested in the Imagen paper.
Resources for more information: GitHub Repository, Paper.
Cite as:
      @InProceedings{Rombach_2022_CVPR,
          author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
          title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
          booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
          month     = {June},
          year      = {2022},
          pages     = {10684-10695}
      }
